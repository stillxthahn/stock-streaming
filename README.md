# Realtime Data Streaming | Data Engineering Project

## Introduction 
This project is my self-learning projects that utilize technological stack to establish an end-to-end data processing pipeline. 
The workflow includes: 
- Producing persistent data in **MySQL** using an API built with **Flask**.
- Identify and track changes to data in a database using **Debezium**.
- Read the streaming data from **Kafka** topic using **PySpark** (Spark Streaming).
- Write the streaming data to **AWS S3**.
- 
- Querying the data with **AWS Athena**.

The entire pipeline is encapsulated within **Docker** containers, affording a streamlined and portable deployment mechanism. 

## System Architecture

